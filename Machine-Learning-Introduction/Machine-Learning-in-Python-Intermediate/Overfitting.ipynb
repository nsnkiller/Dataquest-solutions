{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore overfitting, we'll use a dataset on cars which contains 7 numerical features that could have an effect on a car's fuel efficiency:\n",
    "\n",
    "* cylinders -- the number of cylinders in the engine.\n",
    "* displacement -- the displacement of the engine.\n",
    "* horsepower -- the horsepower of the engine.\n",
    "* weight -- the weight of the car.\n",
    "* acceleration -- the acceleration of the car.\n",
    "* model year -- the year that car model was released (e.g. 70 corresponds to 1970).\n",
    "* origin -- where the car was manufactured (0 if North America, 1 if Europe, 2 if Asia).\n",
    "\n",
    "The mpg column is our target column and is the one we want to predict using the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\", \"car name\"]\n",
    "cars = pd.read_table(\"auto-mpg.data\", delim_whitespace=True, names=columns)\n",
    "filtered_cars = cars[cars['horsepower'] != '?'].copy()\n",
    "filtered_cars['horsepower'] = filtered_cars['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    float64\n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car name      398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "cars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 392 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           392 non-null    float64\n",
      " 1   cylinders     392 non-null    int64  \n",
      " 2   displacement  392 non-null    float64\n",
      " 3   horsepower    392 non-null    float64\n",
      " 4   weight        392 non-null    float64\n",
      " 5   acceleration  392 non-null    float64\n",
      " 6   model year    392 non-null    int64  \n",
      " 7   origin        392 non-null    int64  \n",
      " 8   car name      392 non-null    object \n",
      "dtypes: float64(5), int64(3), object(1)\n",
      "memory usage: 30.6+ KB\n"
     ]
    }
   ],
   "source": [
    "filtered_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of understanding overfitting is understanding **bias** and <b>variance</b>. **Bias** and **variance** make up the 2 observable sources of error in a model that we can indirectly control.\n",
    "\n",
    "Bias describes error that results in bad assumptions about the learning algorithm. For example, assuming that only one feature, like a car's weight, relates to a car's fuel efficiency will lead you to fit a simple, univariate regression model that will result in high bias. The error rate will be high since a car's fuel efficiency is affected by many other factors besides just its weight.\n",
    "\n",
    "Variance describes error that occurs because of the variability of a model's predicted values. If we were given a dataset with 1000 features on each car and used every single feature to train an incredibly complicated multivariate regression model, we will have low bias but high variance.\n",
    "\n",
    "In an ideal world, we want low bias and low variance but in reality, there's always a tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Jupyter](./bias-variance-tradeoff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Jupyter](./bias-and-variance.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721484.7090075159"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_cars['weight'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(cols):\n",
    "    x = filtered_cars[cols]\n",
    "    y = filtered_cars['mpg']\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x, y)\n",
    "    preds = lr.predict(x)\n",
    "    \n",
    "    mse = mean_squared_error(y, preds)\n",
    "    variance = preds.var()\n",
    "    \n",
    "    return(mse, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.02017956815553 36.742558874160174\n",
      "18.6766165974193 42.08612184489639\n"
     ]
    }
   ],
   "source": [
    "cyl_mse, cyl_var = train_and_test(['cylinders'])\n",
    "weight_mse, weight_var = train_and_test(['weight'])\n",
    "\n",
    "print(cyl_mse, cyl_var)\n",
    "print(weight_mse, weight_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_mse, one_var = train_and_test([\"cylinders\"])\n",
    "\n",
    "two_mse, two_var = train_and_test([\"cylinders\", \"displacement\"])\n",
    "\n",
    "three_mse, three_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "\n",
    "four_mse, four_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "\n",
    "five_mse, five_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "\n",
    "six_mse, six_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "\n",
    "seven_mse, seven_var = train_and_test([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.02017956815553 36.742558874160174\n",
      "21.282057055586364 39.4806813867294\n",
      "20.25295483971423 40.50978360260138\n",
      "17.763860571843846 42.99887787047188\n",
      "17.761396105406217 43.00134233690938\n",
      "11.590170981415229 49.17256746090048\n",
      "10.847480945000449 49.91525749731511\n"
     ]
    }
   ],
   "source": [
    "print(one_mse, one_var)\n",
    "print(two_mse, two_var)\n",
    "print(three_mse, three_var)\n",
    "print(four_mse, four_var)\n",
    "print(five_mse, five_var)\n",
    "print(six_mse, six_var)\n",
    "print(seven_mse, seven_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multivariate regression models you trained got progressively better at reducing the amount of error.\n",
    "\n",
    "A good way to detect if your model is overfitting is to compare the <b>in-sample error</b> and the **out-of-sample error**, or the training error with the test error. So far, we calculated the in sample error by testing the model over the same data it was trained on. To calculate the out-of-sample error, we need to test the data on a test set of data. We unfortunately don't have a separate test dataset and we'll instead use cross validation.\n",
    "\n",
    "If a model's cross validation error (out-of-sample error) is much higher than the in sample error, then your data science senses should start to tingle. This is the first line of defense against overfitting and is a clear indicator that the trained model doesn't generalize well outside of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_cross_val(cols): \n",
    "    lr = LinearRegression()\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=3)\n",
    "    X = filtered_cars[cols]\n",
    "    y = filtered_cars['mpg']\n",
    "    mses = []\n",
    "    variance_values = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.iloc[list(train_index)], X.iloc[list(test_index)]\n",
    "        y_train, y_test = y.iloc[list(train_index)], y.iloc[list(test_index)]\n",
    "        lr.fit(X_train, y_train)\n",
    "        preds = lr.predict(X_test)\n",
    "        mses.append(mean_squared_error(y_test, preds))\n",
    "        variance_values.append(preds.var())    \n",
    "    return(np.mean(mses), np.mean(variance_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_mse, two_var = train_and_cross_val(['cylinders', 'displacement'])\n",
    "\n",
    "three_mse, three_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\"])\n",
    "\n",
    "four_mse, four_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\"])\n",
    "\n",
    "five_mse, five_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\"])\n",
    "\n",
    "six_mse, six_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\"])\n",
    "\n",
    "seven_mse, seven_var = train_and_cross_val([\"cylinders\", \"displacement\", \"horsepower\", \"weight\", \"acceleration\", \"model year\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.02017956815553 36.742558874160174\n",
      "21.584370274954377 38.90252531375603\n",
      "20.655622193882955 40.091287956606955\n",
      "18.169683239081888 42.50764364364437\n",
      "18.283038517172052 42.59873630014682\n",
      "12.099685425467126 48.92824696771807\n",
      "11.418131971812064 49.90431373098731\n"
     ]
    }
   ],
   "source": [
    "print(one_mse, one_var)\n",
    "print(two_mse, two_var)\n",
    "print(three_mse, three_var)\n",
    "print(four_mse, four_var)\n",
    "print(five_mse, five_var)\n",
    "print(six_mse, six_var)\n",
    "print(seven_mse, seven_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting cross-validation error vs. cross-validation variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(2,8)\n",
    "y1 = [two_mse, three_mse, four_mse, five_mse, six_mse, seven_mse]\n",
    "y2 = [two_var, three_var, four_var, five_var, six_var, seven_var]\n",
    "\n",
    "plt.scatter(x, y1, c='red')\n",
    "plt.scatter(x, y2, c='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the higher order multivariate models overfit in relation to the lower order multivariate models, the in-sample error and out-of-sample didn't deviate by much. The best model was around **50%** more accurate than the simplest model. On the other hand, the overall variance increased around **25%** as we increased the model complexity. This is a really good starting point, but your work is not done! The increased variance with the increased model complexity means that your model will have more unpredictable performance on truly new, unseen data.\n",
    "\n",
    "If you were working on this problem on a data science team, you'd need to confirm the predictive accuracy of the model using completely new, unobserved data (e.g. maybe from cars from later years). Since often you can't wait until a model is deployed in the wild to know how well it works, the exploration we did in this mission helps you approximate a model's real world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
