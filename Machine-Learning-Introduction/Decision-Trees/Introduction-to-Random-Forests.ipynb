{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Model Predictions With Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is a kind of ensemble model. Ensembles combine the predictions of multiple models to create a more accurate final prediction. We'll make a simple ensemble to see how they work.\n",
    "\n",
    "Let's create two decision trees with slightly different parameters:\n",
    "\n",
    "* One with min_samples_leaf set to 2\n",
    "* One with max_depth set to 5\n",
    "Then, we'll check their accuracies separately. On the next screen, we'll combine their predictions and compare the combined accuracy with the individual accuracies of both trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv('income.csv')\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"education_num\", \"marital_status\", \"occupation\", \"relationship\",\n",
    "           \"race\", \"sex\", \"hours_per_week\", \"native_country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    income[col] = pd.Categorical(income[col]).codes\n",
    "\n",
    "income['high_income'] = pd.Categorical(income['high_income']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(income[columns], income['high_income'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=5)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6962823579658807\n",
      "0.6777293380407088\n"
     ]
    }
   ],
   "source": [
    "auc1 = roc_auc_score(y_test, clf.predict(X_test))\n",
    "auc2 = roc_auc_score(y_test, clf2.predict(X_test))\n",
    "\n",
    "print(auc1)\n",
    "print(auc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Our Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7251618416781492"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict_proba(X_test)[:,1]\n",
    "predictions2 = clf2.predict_proba(X_test)[:,1]\n",
    "\n",
    "preds = np.round((predictions+predictions2)/2)\n",
    "\n",
    "roc_auc_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Ensembling Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the previous screen, the combined predictions of the two trees had a higher AUC than that of either tree on its own:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                     settings                    | train AUC | test AUC |\n",
    "|:-----------------------------------------------:|:---------:|:--------:|\n",
    "| default (min_samples_split: 2, max_depth: None) | 0.947     | 0.694    |\n",
    "| min_samples_split: 13                           | 0.843     | 0.700    |\n",
    "| min_samples_split: 13, max_depth: 7             | 0.748     | 0.7744   |\n",
    "| min_samples_split: 100, max_depth: 2            | 0.662     | 0.655    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To intuitively understand why this makes sense, think about two people with the same level of talent. One learned programming in college, while the other learned it on her own (let's say using Dataquest!).\n",
    "\n",
    "If we give both of them the same project, they'll approach it in slightly different ways, due to their different experiences. They may both produce code that achieves the same result, but one may run faster in certain areas. The other may have a better interface. Even though both of them have about the same level of talent, their solutions are stronger in different areas because they approached the problem differently.\n",
    "\n",
    "If we combine the best parts of both of their projects, we'll end up with a stronger combined project.\n",
    "\n",
    "Ensembling is exactly the same. The models are approaching the same problem in slightly different ways, and building different trees because we used different parameters for each one. Each tree makes different predictions in different areas. Even though both trees have about the same accuracy, when we combine them, the result is stronger because it leverages the strengths of both approaches.\n",
    "\n",
    "The more \"diverse\" or dissimilar the models we use to construct an ensemble are, the stronger their combined predictions will be (assuming that all of the models have about the same accuracy). Ensembling a decision tree and a logistic regression model, for example, will result in stronger predictions than ensembling two decision trees with similar parameters. That's because those two models use very different approaches to arrive at their answers.\n",
    "\n",
    "On the other hand, if the models we ensemble are very similar in how they make predictions, ensembling will result in a negligible boost.\n",
    "\n",
    "Ensembling models with very different accuracies generally won't improve overall accuracy. Ensembling a model with a .75 AUC and a model with a .85 AUC on a test set will usually result in an AUC somewhere in between the two original values. There's a way around this that we'll discuss later on, which we call weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Variation With Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest is an ensemble of decision trees. If we don't make any modifications to the trees, each tree will be exactly the same, so we'll get no boost when we ensemble them. In order to make ensembling effective, we have to introduce variation into each individual decision tree model.\n",
    "\n",
    "If we introduce variation, each tree will be be constructed slightly differently, and will therefore make different predictions. This variation is what puts the \"random\" in \"random forest.\"\n",
    "\n",
    "There are two main ways to introduce variation in a random forest -- bagging and random feature subsets. We'll dive into bagging first.\n",
    "\n",
    "In a random forest, we don't train each tree on the entire data set. **We train it on a random sample of the data, or a \"`bag`,\"** instead. We perform this sampling with replacement, which means that after we select a row from the data we're sampling, we put the row back in the data so it can be picked again. Some rows from the original data may appear in the \"bag\" multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7415762848252972"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll build 10 trees\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 60% of the number of original rows\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 60% of the rows from train, sampling with replacement\n",
    "    # We set a random state to ensure we'll be able to replicate our results\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample in every loop\n",
    "    # That would make all of our trees the same\n",
    "    bag = X_train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    # Fit a decision tree model to the \"bag\"\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2)\n",
    "    clf.fit(bag[columns], y_train[bag.index])\n",
    "    \n",
    "    # Using the model, make predictions on the test data\n",
    "    predictions.append(clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "preds = np.round(sum(predictions)/len(predictions))\n",
    "                       \n",
    "roc_auc_score(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Subsets in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also repeat our random subset selection process in scikit-learn. We just set the splitter parameter on DecisionTreeClassifier to \"random\", and the max_features parameter to \"auto\". If we have N columns, this will pick a subset of features of size \n",
    "$\\sqrt{N}$\n",
    ", compute the Gini coefficient for each (this is similar to information gain), and split the node on the best column in the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7487868062537482\n"
     ]
    }
   ],
   "source": [
    "# We'll build 10 trees\n",
    "tree_count = 10\n",
    "\n",
    "# Each \"bag\" will have 60% of the number of original rows\n",
    "bag_proportion = .6\n",
    "\n",
    "predictions = []\n",
    "for i in range(tree_count):\n",
    "    # We select 60% of the rows from train, sampling with replacement\n",
    "    # We set a random state to ensure we'll be able to replicate our results\n",
    "    # We set it to i instead of a fixed value so we don't get the same sample every time\n",
    "    bag = X_train.sample(frac=bag_proportion, replace=True, random_state=i)\n",
    "    \n",
    "    # Fit a decision tree model to the \"bag\"\n",
    "    clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=2, splitter='random', max_features='auto')\n",
    "    clf.fit(bag[columns], y_train[bag.index])\n",
    "    \n",
    "    # Using the model, make predictions on the test data\n",
    "    predictions.append(clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "combined = np.sum(predictions, axis=0) / 10\n",
    "rounded = np.round(combined)\n",
    "\n",
    "print(roc_auc_score(y_test, rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Putting it All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                     settings                    | train AUC | test AUC |\n",
    "|:-----------------------------------------------:|:---------:|:--------:|\n",
    "| default (min_samples_split: 2, max_depth: None) | 0.947     | 0.694    |\n",
    "| min_samples_split: 13                           | 0.843     | 0.700    |\n",
    "| min_samples_split: 13, max_depth: 7             | 0.748     | 0.7744   |\n",
    "| min_samples_split: 100, max_depth: 2            | 0.662     | 0.655    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746084784139288\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5, random_state=1, min_samples_leaf=2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predes = clf.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, predes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweaking Parameters to Increase Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can tweak some of the parameters for random forests, including:\n",
    "\n",
    "* min_samples_leaf\n",
    "* min_samples_split\n",
    "* max_depth\n",
    "* max_leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552550543495277\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predes = clf.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, predes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6605350228576031\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=2, max_depth=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predes = clf.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, predes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the major advantages of random forests over single decision trees is that they tend to overfit less. Although each individual decision tree in a random forest varies widely, the average of their predictions is less sensitive to the input data than a single tree is. This is because while one tree can construct an incorrect and overfit model, the average of 100 or more trees will be more likely to hone in on the signal and ignore the noise. The signal will be the same across all of the trees, whereas each tree will hone in on the noise differently. This means that the average will discard the noise and keep the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8177223176546391\n",
      "0.7207468039095158\n",
      "0.7934448046614619\n",
      "0.7556351223804341\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=1, min_samples_leaf=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_train)\n",
    "print(roc_auc_score(y_train, predictions))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, predictions))\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_train)\n",
    "print(roc_auc_score(y_train, predictions))\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552550543495277\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=2, n_jobs=4)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predes = clf.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, predes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552550543495277\n",
      "Wall time: 6.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = RandomForestClassifier(n_estimators=150, random_state=1, min_samples_leaf=2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predes = clf.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test, predes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the code cell from the previous screen, overfitting decreased with a random forest, and accuracy went up overall.\n",
    "\n",
    "While the random forest algorithm is incredibly powerful, it isn't applicable to all tasks. The main strengths of a random forest are:\n",
    "\n",
    "* Very accurate predictions - Random forests achieve near state-of-the-art performance on many machine learning tasks. Along with neural networks and gradient-boosted trees, they're typically one of the top-performing algorithms.\n",
    "* Resistance to overfitting - Due to their construction, random forests are fairly resistant to overfitting. We still need to set and tweak parameters like max_depth though.\n",
    "\n",
    "The main weaknesses of using a random forest are:\n",
    "\n",
    "* They're difficult to interpret - Because we're averaging the results of many trees, it can be hard to figure out why a random forest is making predictions the way it is.\n",
    "* They take longer to create - Making two trees takes twice as long as making one, making three takes three times as long, and so on. Fortunately, we can exploit multicore processors to parallelize tree construction. Scikit allows us to do this through the n_jobs parameter on RandomForestClassifier. We'll discuss parallelization in greater detail later on.\n",
    "\n",
    "Given these trade-offs, it makes sense to use random forests in situations where accuracy is of the utmost importance; being able to interpret or explain the decisions the model is making isn't key. In cases where time is of the essence or interpretability is important, a single decision tree may be a better choice.\n",
    "\n",
    "Next up in this course is a guided project where you'll explore using random forests to predict bike rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
